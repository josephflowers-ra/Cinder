{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephflowers-ra/Cinder/blob/main/Copy_of_Unsloth_alpaca_A100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJAx6D0QE6Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdt6pirkeCtx",
        "outputId": "51d4532b-157d-44ab-ad30-4261c01c29ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -v -r /content/drive/MyDrive/tllama/official /content/"
      ],
      "metadata": {
        "id": "fFtg_oddsLY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTSV6PLnHW6B"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/content/official/\"\n",
        "max_seq_length = 2048\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.01\n",
        "max_steps = 120*2\n",
        "warmup_steps = 10\n",
        "batch_size = 12\n",
        "num_train_epochs = 2\n",
        "gradient_accumulation_steps = 4\n",
        "lr_scheduler_type = \"linear\"\n",
        "optimizer = \"adamw_8bit\"\n",
        "use_gradient_checkpointing = True\n",
        "random_state = 3407"
      ],
      "metadata": {
        "id": "bQXaQb8_Wmue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZTmNbC0H5hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5dffc1-ba2d-48ff-fb63-3b2e8c0319ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/unsloth/__init__.py:67: UserWarning: CUDA is not linked properly.\n",
            "We shall run `ldconfig /usr/lib64-nvidia` to try to fix it.\n",
            "  warnings.warn(\n",
            "==((====))==  Unsloth: Fast Llama patching release 2024.1\n",
            "   \\\\   /|    GPU: Tesla V100-SXM2-16GB. Max memory: 15.773 GB\n",
            "O^O/ \\_/ \\    CUDA capability = 7.0. Xformers = 0.0.22.post7. FA = False.\n",
            "\\        /    Pytorch version: 2.1.0+cu121. CUDA Toolkit = 12.1\n",
            " \"-____-\"     bfloat16 = FALSE. Platform = Linux\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLlamaModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "HAS_BFLOAT16 = torch.cuda.is_bf16_supported()\n",
        "\n",
        "model, tokenizer = FastLlamaModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl3agZgoIG65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e661b06f-8b8d-4426-82a9-f248c26fad66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.1 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLlamaModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Currently only supports dropout = 0\n",
        "    bias = \"none\",    # Currently only supports bias = \"none\"\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    max_seq_length = max_seq_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Alpaca dataset preparation\n",
        "alpaca_prompt = \"\"\"<s>\n",
        "<|system|>\n",
        "{}\n",
        "</s>\n",
        "<|user|>\n",
        "{}\n",
        "</s>\n",
        "<|assistant|>\n",
        "{}</s>\"\"\"\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        text = alpaca_prompt.format(instruction, input, output)\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5aa10b51e09f4559b389e519efeb28a0",
            "8c29618180264347aaa1094ca19e03ea",
            "cd03715762fc405cb4689a2441b1468a",
            "192488d8263849ae903db6baceec14a3",
            "abcd1e8540c34d208c365a6443e135d7",
            "9a89eb7331464ea3859a9244c28dae09",
            "413f0324254e46798a439e92fb03e924",
            "bc21b1bcfb194a18bcd66aebf893bdd8",
            "2fbf582a81db482fb0f58435729b5606",
            "3e671aa649484811b60ee56ab23c4223",
            "ab3da486fbc74b179912f710acd58b38"
          ]
        },
        "id": "yxCHPF3jXtJx",
        "outputId": "1cd50297-4696-4ad2-a830-a4dc17a83930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/51760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aa10b51e09f4559b389e519efeb28a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset\n",
        "dataset = TextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/drive/MyDrive/cinder_smart_system.txt\",\n",
        "    block_size = max_seq_length,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV-kBLVjuYIP",
        "outputId": "dbe496cb-7746-4d15-bc5a-e55c36f9869e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (28429741 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nX3SL7cI2fZ"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity_info()\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    tokenizer = tokenizer,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = batch_size,\n",
        "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "        warmup_steps = warmup_steps,\n",
        "        max_steps = max_steps,\n",
        "        learning_rate = learning_rate,\n",
        "        fp16 = not HAS_BFLOAT16,\n",
        "        bf16 = HAS_BFLOAT16,\n",
        "        logging_steps = 1,\n",
        "        output_dir = \"outputs\",\n",
        "        optim = optimizer,\n",
        "        weight_decay = weight_decay,\n",
        "        lr_scheduler_type = lr_scheduler_type,\n",
        "        seed = random_state,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEKvSiA5QBF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2bf17a-6853-4941-d493-7ee6d7ea7402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla V100-SXM2-16GB. Max memory = 15.773 GB.\n",
            "0.824 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jZyjKIUQCvL"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/model_output/final_model\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "CvcSB1JdGf0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r -v /content/lora_model /content/drive/MyDrive/tllama/lora_model"
      ],
      "metadata": {
        "id": "KxBloOry9nMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r -v /content/model_output/final_model /content/drive/MyDrive/tllama/alp_model_output"
      ],
      "metadata": {
        "id": "4-Yy7nRbIrE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " merged_model = merged.merge_and_unload()"
      ],
      "metadata": {
        "id": "8qIs1kWn-Rr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "# model.push_to_hub(\"your_name/lora_model\") # Online saving"
      ],
      "metadata": {
        "id": "cvlnT0YHxa9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "wmfeGierxwLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "model = PeftModel.from_pretrained(model, \"lora_model\")\n",
        "model.merge_and_unload()\n",
        "model.save_pretrained(\"official2\")"
      ],
      "metadata": {
        "id": "ICID093kyNrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer('Black holes are formed when', return_tensors = 'pt')\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAuiHCYJykH9",
        "outputId": "f95b7093-d362-4875-974d-c314854f43b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> Black holes are formed when massive stars collapse under their own gravity, creating a point of infinite density called a singularity.\\n\\nThe event horizon is the point at which an object or a region of space-time can no longer escape the gravitational pull of a black hole. Once an object crosses the event horizon, it is inexorably drawn into the black hole, and its matter is compressed to a point of infinite density called a singularity.\\n\\nBlack holes have a significant impact on the surrounding space and time. They can distort the fabric of spacetime itself, creating a region of spacetime known as a singularity. This singularity can be observed and studied using advanced instruments, such as X-ray telescopes and gravitational wave detectors.\\n\\nBlack holes play a crucial role in the evolution of galaxies and the broader universe. They are believed to be responsible for the formation of galaxies and the large-scale structure of the universe. Additionally, black holes are key players in the process of galaxy formation and evolution.\\n\\nOverall, black holes are incredibly dense objects with strong gravitational forces that shape the fate of matter and space in the universe. They are a fundamental aspect of the cosmos and continue to be a subject of intense scientific study.\"\\n 1.33</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "cliCdqEI_YUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"official2\")"
      ],
      "metadata": {
        "id": "I_mwvEIeBRh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained('/content/official/', load_in_8bit=True, torch_dtype=torch.float16, device_map='auto')\n",
        "\n",
        "#base_model = prepare_model_for_int8_training(base_model)\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(model, \"lora_model\")\n",
        "\n",
        "\n",
        "\n",
        "peft_model.save_pretrained(lora_adapter, save_adapter=True, save_config=True)\n",
        "\n",
        "model_to_merge = PeftModel.from_pretrained(AutoModelForCausalLM.from_pretrained(base_model).to('cuda'), lora_adapter)\n",
        "\n",
        "merged_model = model_to_merge.merge_and_unload()\n",
        "merged_model.save_pretrained(merged_model)"
      ],
      "metadata": {
        "id": "mBYdQYpg_TtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r -v /content/official/ /content/drive/MyDrive/tllama/official1"
      ],
      "metadata": {
        "id": "Oz0xxVeYBy9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gup9SDYzQDyg"
      },
      "outputs": [],
      "source": [
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5aa10b51e09f4559b389e519efeb28a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c29618180264347aaa1094ca19e03ea",
              "IPY_MODEL_cd03715762fc405cb4689a2441b1468a",
              "IPY_MODEL_192488d8263849ae903db6baceec14a3"
            ],
            "layout": "IPY_MODEL_abcd1e8540c34d208c365a6443e135d7"
          }
        },
        "8c29618180264347aaa1094ca19e03ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a89eb7331464ea3859a9244c28dae09",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_413f0324254e46798a439e92fb03e924",
            "value": "Map: 100%"
          }
        },
        "cd03715762fc405cb4689a2441b1468a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc21b1bcfb194a18bcd66aebf893bdd8",
            "max": 51760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fbf582a81db482fb0f58435729b5606",
            "value": 51760
          }
        },
        "192488d8263849ae903db6baceec14a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e671aa649484811b60ee56ab23c4223",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ab3da486fbc74b179912f710acd58b38",
            "value": " 51760/51760 [00:00&lt;00:00, 126833.70 examples/s]"
          }
        },
        "abcd1e8540c34d208c365a6443e135d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a89eb7331464ea3859a9244c28dae09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413f0324254e46798a439e92fb03e924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc21b1bcfb194a18bcd66aebf893bdd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fbf582a81db482fb0f58435729b5606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e671aa649484811b60ee56ab23c4223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3da486fbc74b179912f710acd58b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}